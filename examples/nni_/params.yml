# lightgbm
lgb:
    # 整数
    num_leaves:
        _type: randint
        _value: [15, 31]
    bagging_freq:
        _type: randint
        _value: [1, 16]
    min_child_samples:
        _type: randint
        _value: [5, 100]

    # 小数
    bagging_fraction:
        _type: uniform
        _value: [0.7, 1.0]
    feature_fraction:
        _type: uniform
        _value: [0.7, 1]
    lambda_l1:
        _type: uniform # loguniform
        _value: [1e-8, 10]
    lambda_l2:
        _type: uniform # loguniform
        _value: [1e-8, 10]
    min_split_gain:
        _type: uniform # loguniform
        _value: [1e-8, 1]
    min_child_weight:
        _type: uniform # loguniform
        _value: [1e-8, 1]

lgb.LGBMClassifier:
    boosting_type: 'gbdt'
    objective: None
    n_estimators: 10000
    n_jobs: -1
    #    random_state=666,
    #    bagging_seed=0,
    #    feature_fraction_seed=0

    # 整数
    num_leaves:
        _type: randint
        _value: [15, 31]
    subsample_freq:
        _type: randint
        _value: [1, 16]
    min_child_samples:
        _type: randint
        _value: [5, 100]

    # 小数
    learning_rate:
        _type: choice
        _value: [0.01, 0.05, 0.1, 0.2]
    subsample:
        _type: uniform
        _value: [0.7, 1.0]
    colsample_bytree:
        _type: uniform
        _value: [0.7, 1]
    reg_alpha:
        _type: uniform # loguniform
        _value: [1e-8, 10]
    reg_lambda:
        _type: uniform # loguniform
        _value: [1e-8, 10]
    min_split_gain:
        _type: uniform # loguniform
        _value: [1e-8, 1]
    min_child_weight:
        _type: uniform # loguniform
        _value: [1e-8, 1]

lgb.LGBMRegressor: {}
lgb.LGBMRanker: {}




# xgboost
# catboost





